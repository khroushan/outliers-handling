\documentclass{article}
\usepackage{amsmath}
\usepackage{graphics}
\graphicspath{ {./figs/} }

\begin{document}
%%%%%%%%%% 
\section{Introduction}

In the last few chapters, we have tried to develop a model to estimate the product cost. There are two main problems that can hinder the estimator to achieve a high performance, namely, presence of {\bf outliers} and {\bf novelty}. These two concepts prevent the model to make a good estimation either by decieving or by not approprietly extrapolating to the new data points. What an outlier and a novelty datapoints have in common is that both deviate substantially from the statistic metrics of the dataset. 

%%%%%%%%%% 
\section{Definition: Outliers vs. Novelty}

\texttt{Study last three papers and sklearn documentation}


Notice that the target value of outliers is a random number in the same expected range. This is a sensible assumption, otherwise if the target has a same form of functionality of the features, even out of range, lead to the same trained model.


\begin{enumerate}
\item Add a formal definition for outlier and novelty.
\item Make few actual or fictitious, relevant or errelevant examples from industry.
\item How these two concepts are different from theoritical and practical perspective?
\end{enumerate}

\begin{figure}[h]
  \includegraphics[textwidth=0.7\textwidth]{outlier_vs_novelty}
    \caption{Outliers can be identified as points in the dataset that deviates from the common statistical behaviour of the dataset. They can be regarded as extra level of rendomness that can generate them but the process in itself is random. In contrast novelty are generated by a new introduced process that will be part of data but different from the majority.(left) outliers (right) novelty }
\end{figure}

Here we identify two specific forms of outliers:
\begin{itemize}  
\item Outliers are uniformly distributated in range of inliers
\item Outliers are isolated in the feature space
\end{itemize}

%%%%%%%%%%
\section{Approaches}
Here we take two main approches toward the problem. (i){\bf Supervised} and (ii) {\bf Unsupervised} methods.


%%%%%%%%%% 
\section{Unsupervised Approaches}
What are the advantages?

%%%%%
\subsection{Simple statistical tools}

Comparing the distance of data point to the center of data and variation of data.

%%%%%
\subsection{}

Extend the idea from previous section for a non-unimodal data distribution. In such cases the previous recipe fails. What we can do is to compare the distance with the local density.

The local density is determined by {\bf KNN}

%%%%%
\subsection{Isolation Forest}

Outliers have shorter tree branch length compare to the outliers

%%%%%%%%%% 
\section{Supervised}

%%%%%
\subsection{Robust Regression on clustered data}

The approach that we present in this section is to build a robust regression by mean of clustering. The process starts by applying a {\em proper} clustering method to the dataset.  Two different outcomes are expected:

\begin{enumerate}
\item \label{few-cluster} There are few clusters that contain the majority of the dataset.
\item \label{uniform-cluster} Dataset is distributed among clusters almost uniformly.
\end{enumerate}

If the outcome \ref{few-cluster}  happens, the regression model of interest will be trained on the sorted clusters based on their population from large to small. The test error will be measured every time a new cluster is added to the training dataset. The accumulated clusters with minimum generalization error will be the final dataset to train a regression model.

If the outcome \ref{uniform-cluster}  happens, then there would be no preferance among the clusters to start with. The best course of action would be similar to {\em cross validation} by taking one cluster  out and train on the rests. The best model can be reached either by taking average of parameters if a model is linear,  or exclude the cluster that when it is added to the training dataset increase the generalization error dramaticly. The later approach is tacken when avering of parameters does not make any sense such as case of decision tree. 

(number of cluster is large to make sure that the elbow criteria is passed).


\subsection{Curse of Dimensionality}
When the number of features is too large, the clustering method lose its reliability.


\subsection{Algorithm}
\begin{itemize}
\item Clustering with large number of clusters
\item Apply clustering, make sure you pass elbow criteria.
\item Sort cluster based on their population.
\item Start training from high population accumulatively.
\item Measure generalization error.
\item Plot error agains clusters.
\end{itemize}

%%%%%%%%%%
\section{Summary}


%%%%%%%%%% 
\begin{thebibliography}{10}

\bibitem{lof} Breunig, Markus M., et al. ``LOF: identifying density-based local outliers.'' {\em Proceedings of the 2000 ACM SIGMOD international conference on Management of data.} 2000.
  
\bibitem{iso_forest} Liu, Fei Tony, Kai Ming Ting, and Zhi-Hua Zhou. ``Isolation forest.'' {\em 2008 eighth ieee international conference on data mining. IEEE,} 2008.

\bibitem{high_dim} Sch\"{o}lkopf, Bernhard, et al. ``Estimating the support of a high-dimensional distribution.'' {\em Neural computation 13.7} (2001): 1443-1471.

\bibitem{outlier_survey}  Hodge, Victoria, and Jim Austin. ``A survey of outlier detection methodologies.'' {\em Artificial intelligence review 22.2} (2004): 85-126.

\bibitem{advers_novelty_detection} Sabokrou, Mohammad, et al. ``Adversarially learned one-class classifier for novelty detection.'' {\em Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}. 2018.

\bibitem{rare_event} Carreno, Ander, Inaki Inza, and Jose A. Lozano. ``Analyzing rare event, anomaly, novelty and outlier detection terms under the supervised classification framework.'' {\em Artificial Intelligence Review} (2019): 1-20.
\end{thebibliography}

\end{document}
